<!DOCTYPE html>
<html>
  <head>
    <title>Spark & Mapreduce</title>
  </head>
  <body>

      <h1> Hadoop MapReduce so với Apache Spark </h1>
      <p>Thuật ngữ dữ liệu lớn đã tạo ra rất nhiều sự cường điệu đã có trong thế giới kinh doanh. Hadoop và Spark đều là các khung dữ liệu lớn; họ cung cấp một số công cụ phổ biến nhất được sử dụng để thực hiện các tác vụ lớn liên quan đến dữ liệu lớn. Trong bài viết này, chúng tôi sẽ đề cập đến sự  khác biệt giữa Spark và Hadoop MapReduce. </p>
      <h2>Giới thiệu</h2>
      <p>Spark : Nó là một khung dữ liệu lớn nguồn mở. Nó cung cấp một công cụ xử lý dữ liệu có mục đích chung nhanh hơn và nhiều hơn. Spark về cơ bản được thiết kế để tính toán nhanh. Nó cũng bao gồm một loạt các khối lượng công việc - ví dụ, lô, tương tác, lặp và phát trực tuyến.</br>
        Hadoop MapReduce :  Đây cũng là một khung nguồn mở để viết các ứng dụng. Nó cũng xử lý dữ liệu có cấu trúc và không cấu trúc được lưu trữ trong HDFS. Hadoop MapReduce được thiết kế theo cách xử lý một khối lượng lớn dữ liệu trên một cụm phần cứng hàng hóa. MapReduce có thể xử lý dữ liệu trong chế độ hàng loạt.</p>
  </body>
</html>
